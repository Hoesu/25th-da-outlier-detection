{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import logging\n",
    "import platform\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.utils.data\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from utils.model import VAE\n",
    "from utils.dataset import OutlierDataset\n",
    "\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(config) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        - csv파일 데이터프레임으로 불러오기.\n",
    "        - value를 제외한 모든 칼럼을 무시.\n",
    "        \"\"\"\n",
    "        data_path = config['data_path']\n",
    "        try:\n",
    "            data = pd.read_csv(data_path, usecols=['value'])\n",
    "        except Exception as e:\n",
    "            print(f\"csv 파일을 불러오는 도중 문제가 발생했습니다: {e}\")\n",
    "            print(\"config.yaml을 열어 csv 파일 경로가 상대경로로 기입되어 있는지 확인하세요.\")\n",
    "        return data\n",
    "    \n",
    "def load_json(config) -> list[list[int]]:\n",
    "    \"\"\"\n",
    "    - 비교적 이상치의 위험성이 적은 구간에 대한 정보를 담은 json 파일 불러오기.\n",
    "    - csv 파일 경로를 파싱해서 json의 키 값으로 재활용한다.\n",
    "    \"\"\"\n",
    "    data_path = config['data_path']\n",
    "    interval_path = config['interval_path']\n",
    "    dirc_name = data_path.split('/')[1]\n",
    "    file_name = data_path.split('/')[2]\n",
    "    try:\n",
    "        with open(interval_path, 'r') as file:\n",
    "            interval = json.load(file)[dirc_name][file_name]\n",
    "    except Exception as e:\n",
    "        print(f\"json 파일을 불러오는 도중 문제가 발생했습니다: {e}\")\n",
    "        print(\"config.yaml을 열어 csv, json 파일 경로가 상대경로로 기입되어 있는지 확인하세요.\")\n",
    "    return interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_csv(config)\n",
    "intervals = load_json(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.9516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.7770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.6126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.4761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.6497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30116</th>\n",
       "      <td>32.4947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30117</th>\n",
       "      <td>32.1726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30118</th>\n",
       "      <td>32.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30119</th>\n",
       "      <td>32.0694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30120</th>\n",
       "      <td>32.1296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30121 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         value\n",
       "0      31.9516\n",
       "1      32.7770\n",
       "2      32.6126\n",
       "3      32.4761\n",
       "4      32.6497\n",
       "...        ...\n",
       "30116  32.4947\n",
       "30117  32.1726\n",
       "30118  32.0665\n",
       "30119  32.0694\n",
       "30120  32.1296\n",
       "\n",
       "[30121 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1000], [2000, 3000]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_interval(data: pd.DataFrame,\n",
    "                          intervals: list[list[int]]) -> list[pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        - 불러온 구간 정보로 원본 데이터프레임 분할, 분할한 데이터프레임을 리스트에 담아 반환.\n",
    "        - 각각의 분할 구간은 우리가 훈련 데이터로 사용할 수 있는 값들을 의미한다.\n",
    "        \"\"\"\n",
    "        subsets = []\n",
    "        for start, end in intervals:\n",
    "            subset = data.iloc[start:end]\n",
    "            subsets.append(subset)\n",
    "        return subsets\n",
    "\n",
    "def slice_by_window(config, data: list[pd.DataFrame]) -> list[np.ndarray]:\n",
    "    \"\"\"\n",
    "    - 분할된 데이터프레임별로 주어진 윈도우로 스텝 사이즈 만큼 이동하며 데이터 추출.\n",
    "    - 만약에 주어진 구간 안에서 윈도우 설정이 불가능하면 해당 구간을 건너뛴다.\n",
    "    \"\"\"\n",
    "    window_size = config['seq_size']\n",
    "    step_size = config['step_size']\n",
    "    windows = []\n",
    "    for subset in data:\n",
    "        values = subset['value'].to_numpy()\n",
    "        for start in range(0, len(values) - window_size + 1, step_size):\n",
    "            window = values[start:start + window_size]\n",
    "            windows.append(window)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[       value\n",
       " 0    31.9516\n",
       " 1    32.7770\n",
       " 2    32.6126\n",
       " 3    32.4761\n",
       " 4    32.6497\n",
       " ..       ...\n",
       " 995  31.5987\n",
       " 996  31.9012\n",
       " 997  31.6645\n",
       " 998  31.8105\n",
       " 999  31.8217\n",
       " \n",
       " [1000 rows x 1 columns],\n",
       "         value\n",
       " 2000  31.7199\n",
       " 2001  32.2450\n",
       " 2002  31.6883\n",
       " 2003  31.8868\n",
       " 2004  32.0465\n",
       " ...       ...\n",
       " 2995  32.8189\n",
       " 2996  33.0118\n",
       " 2997  32.7250\n",
       " 2998  33.0652\n",
       " 2999  32.6277\n",
       " \n",
       " [1000 rows x 1 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = split_by_interval(data, intervals)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = slice_by_window(config, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data: list[np.ndarray]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        - 모든 값들을 시퀀스 단위로 정규화, [seq_size, batch_size, 1] 차원의 텐서로 반환.\n",
    "        \"\"\"\n",
    "        data_array = np.array(data)\n",
    "        means = data_array.mean(axis=1, keepdims=True)\n",
    "        stds = data_array.std(axis=1, keepdims=True)\n",
    "        normalized_data = (data_array - means) / stds\n",
    "        return torch.tensor(normalized_data, dtype=torch.float32).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6897],\n",
       "         [ 1.4473],\n",
       "         [ 1.0216],\n",
       "         ...,\n",
       "         [ 0.8738],\n",
       "         [ 1.5646],\n",
       "         [-0.7659]],\n",
       "\n",
       "        [[ 0.6821],\n",
       "         [ 1.5753],\n",
       "         [ 0.1827],\n",
       "         ...,\n",
       "         [ 0.2915],\n",
       "         [-1.4896],\n",
       "         [-1.1182]],\n",
       "\n",
       "        [[ 0.5173],\n",
       "         [ 0.0119],\n",
       "         [ 0.2152],\n",
       "         ...,\n",
       "         [-0.7234],\n",
       "         [ 0.5486],\n",
       "         [-0.3418]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.6360],\n",
       "         [-1.1288],\n",
       "         [-2.2980],\n",
       "         ...,\n",
       "         [ 0.2688],\n",
       "         [ 1.2236],\n",
       "         [-1.4799]],\n",
       "\n",
       "        [[ 0.0577],\n",
       "         [-1.1270],\n",
       "         [-0.7965],\n",
       "         ...,\n",
       "         [ 0.4339],\n",
       "         [ 0.4881],\n",
       "         [ 2.7353]],\n",
       "\n",
       "        [[-0.1102],\n",
       "         [-0.6594],\n",
       "         [-0.0785],\n",
       "         ...,\n",
       "         [ 0.1016],\n",
       "         [ 1.1396],\n",
       "         [-0.1953]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = standardize(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 150, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "outlier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
